{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ac2104a-fe1e-4cd1-a06c-f0c8315f254e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 必要ライブラリのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e2d47f-f876-4bd0-a2d5-56f051b95b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-ai-ml\n",
    "!pip install azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e10ae9e-efc8-477d-8f16-25b66b85c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azureml.core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a1856f-3694-4569-8a12-2b385bf19cb3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 実行元ジョブ用ディレクトリの作成＋ジョブ名の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71504f3c-3061-41ca-9edc-cf624df09c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r template_job dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c873b51e-1192-4fab-8109-6f90d55821c9",
   "metadata": {},
   "source": [
    "# ジョブ名の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2860d10a-65e0-4384-bb2e-ad657c14bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上でコピーした先のディレクトリ名をジョブ名とする\n",
    "# !cp -r template_job test_jobならtest_job\n",
    "pattern_id = \"dummy\"\n",
    "job_name = \"dummy_1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85fdf22-6dc3-4abd-b5e7-35f17d5f0768",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 定数の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd38b63-c10a-46ec-967b-aa309dfe672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098a93a7-b197-44b1-88b7-9b903b1c43f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = f\"{current_directory}/{job_name}\"\n",
    "print(BASE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b90413c-5db4-4b9c-874f-192ca54604a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# azアカウントログイン->ワークスペースの定義、接続"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ef35d0-2cbb-4681-93d8-8fad01f4d758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "#Enter details of your Azure Machine Learning workspace\n",
    "subscription_id = \"\"\n",
    "resource_group = \"\"\n",
    "workspace = \"\"\n",
    "\n",
    "#connect to the workspace\n",
    "ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee52003-a422-4297-8ba8-e10788b39eae",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CCの接続"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8630fde0-ac78-4bf7-a2a1-8ae549425c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "# specify aml compute name.\n",
    "# 4GPU\n",
    "gpu_compute_target = \"\"\n",
    "\n",
    "ml_client.compute.get(gpu_compute_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f0d5e5-51bb-4c27-b79c-0ad50997ce55",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 実行ノードの定義(Dockerfile読込)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a4cfca-d5b5-4909-bfe9-fe88e77e9c8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 環境共通（APT,SFT,SFT_QLoRA）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580ffae1-9e0a-405d-a6a1-52caf9cab409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment, BuildContext\n",
    "\n",
    "custom_env = Environment(\n",
    "    build=BuildContext(path=f\"{BASE_DIR}/config/OSS\"),\n",
    "    name=\"LLM-train-Env\",\n",
    "    description=\"Env to train SFT,QLoRA for OSS LLM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94ca983-8c26-4b3c-8ac7-b754e6676d1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 学習ジョブの設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20acc399-ff7e-44b5-bc7d-70958f8a91b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359615ee-7af6-4401-83a5-d452d6cb1872",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30517d21-3526-43a2-a533-a882f4f92780",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_type = \"SFT\"\n",
    "\n",
    "sub_id = \"\"\n",
    "rg = \"\"\n",
    "ws = \"\"\n",
    "blob = \"\"\n",
    "\n",
    "model_path = \"elyza/ELYZA-japanese-Llama-2-7b-instruct\"\n",
    "output_path = f\"azureml://subscriptions/{sub_id}/resourcegroups/{rg}/workspaces/{ws}/datastores/{blob}/paths/models/pattern_{pattern_id}/\"\n",
    "\n",
    "# 学習データ設定\n",
    "train_data_path = f\"data/train_data.csv\"\n",
    "valid_data_path = f\"data/valid_data.csv\"\n",
    "\n",
    "# job初回起動時はenvはコメントアウトしているほうに変更してください\n",
    "#env = custom_env\n",
    "env = \"LLM-train-Env:1\"\n",
    "\n",
    "# --save_steps 500 \\\n",
    "# --eval_steps 150 \\\n",
    "# --output_dir './outputs' \\\n",
    "cmd = f\"accelerate launch train_script/train_SFT.py \\\n",
    "--model_name_or_path '{model_path}' \\\n",
    "--train_data_path '{train_data_path}' \\\n",
    "--valid_data_path '{valid_data_path}' \\\n",
    "--fp16 False \\\n",
    "--bf16 True \\\n",
    "--tf32 False \\\n",
    "--output_dir ${{outputs.model_output}} \\\n",
    "--num_train_epochs 3 \\\n",
    "--per_device_train_batch_size 1 \\\n",
    "--per_device_eval_batch_size 2 \\\n",
    "--evaluation_strategy 'steps' \\\n",
    "--save_strategy 'steps' \\\n",
    "--save_steps 2500 \\\n",
    "--eval_steps 500 \\\n",
    "--save_total_limit 100 \\\n",
    "--learning_rate 1e-5 \\\n",
    "--weight_decay 0. \\\n",
    "--warmup_ratio 0.03 \\\n",
    "--lr_scheduler_type 'cosine' \\\n",
    "--logging_steps 50 \\\n",
    "--fsdp 'shard_grad_op auto_wrap' \\\n",
    "--fsdp_transformer_layer_cls_to_wrap 'LlamaDecoderLayer' \\\n",
    "--report_to 'mlflow' \\\n",
    "--ddp_timeout 7200\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ca7f58-0d51-4103-9dc9-a869b574ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command, Input, Output\n",
    "\n",
    "# define the command\n",
    "# python3.10 -m torch.distributed.run --nproc_per_node=4 --master_port=12345 train.py --model_name_or_path ${{inputs.base_model}} --data_path ${{inputs.train_data}} --fp16 True --output_dir ./outputs --num_train_epochs 5 --model_max_length 512 --per_device_train_batch_size 2 --per_device_eval_batch_size 2 --gradient_accumulation_steps 3 --evaluation_strategy 'no' --save_strategy 'steps' --save_steps 50000 --save_total_limit 1 --learning_rate 1e-5 --weight_decay 0. --warmup_ratio 0.02 --lr_scheduler_type 'cosine' --logging_steps 1 --fsdp 'shard_grad_op auto_wrap' --tf32 True --report_to 'mlflow'\n",
    "command_job = command(\n",
    "    code=f\"{BASE_DIR}\",\n",
    "    # change point\n",
    "    command=cmd,\n",
    "    environment=env,\n",
    "    compute=f\"{gpu_compute_target}\",\n",
    "    timeout=180000,\n",
    "    outputs={\n",
    "        \"model_output\": Output(\n",
    "            type=\"uri_folder\",\n",
    "            path=output_path,\n",
    "            mode=\"rw_mount\"\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307c6bd1-7bd9-4827-896f-61c9649288ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "## QLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cde137-a3fa-49a6-966c-5638bd0fc456",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_type = \"SFT_QLoRA\"\n",
    "\n",
    "sub_id = \"\"\n",
    "rg = \"\"\n",
    "ws = \"\"\n",
    "blob = \"\"\n",
    "\n",
    "model_path = \"elyza/ELYZA-japanese-Llama-2-7b-instruct\"\n",
    "output_path = f\"azureml://subscriptions/{sub_id}/resourcegroups/{rg}/workspaces/{ws}/datastores/{blob}/paths/models/pattern_{pattern_id}/\"\n",
    "\n",
    "# 学習データ設定\n",
    "# train_data_path = \"azureml://subscriptions/XXX/resourcegroups/YYY/workspaces/ZZZ/datastores/workspaceblobstore/paths/xxx\"\n",
    "# valid_data_path = \"azureml://subscriptions/XXX/resourcegroups/YYY/workspaces/ZZZ/datastores/workspaceblobstore/paths/xxx\"\n",
    "train_data_path = \"data/train_data.csv\"\n",
    "valid_data_path = \"data/valid_data.csv\"\n",
    "\n",
    "# job初回起動時はenvはコメントアウトしているほうに変更してください\n",
    "#env = custom_env\n",
    "env = \"LLM-train-Env:1\"\n",
    "\n",
    "\n",
    "# --eval_steps 150 \\\n",
    "# --save_strategy 'steps' \\\n",
    "# --save_steps 500 \\\n",
    "cmd = f\"accelerate launch train_script/train_SFT_QLoRA.py \\\n",
    "--model_name {model_path} \\\n",
    "--fp16 False \\\n",
    "--bf16 True \\\n",
    "--tf32 False \\\n",
    "--train_data_path {train_data_path} \\\n",
    "--valid_data_path {valid_data_path} \\\n",
    "--output_dir ${{outputs.model_output}} \\\n",
    "--num_train_epochs 3 \\\n",
    "--per_device_train_batch_size 1 \\\n",
    "--per_device_eval_batch_size 2 \\\n",
    "--evaluation_strategy 'steps' \\\n",
    "--eval_steps 500 \\\n",
    "--save_strategy 'steps' \\\n",
    "--save_steps 2500 \\\n",
    "--save_total_limit 10 \\\n",
    "--learning_rate 1e-5 \\\n",
    "--save_strategy steps \\\n",
    "--group_by_length True \\\n",
    "--logging_strategy steps \\\n",
    "--logging_steps 50 \\\n",
    "--weight_decay 0.0 \\\n",
    "--warmup_ratio 0.03 \\\n",
    "--max_grad_norm 0.3 \\\n",
    "--lr_scheduler_type 'cosine' \\\n",
    "--gradient_accumulation_steps 1 \\\n",
    "--report_to 'mlflow'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d5169f-432c-4c41-b754-8b9dc59bc75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command, Input, Output\n",
    "\n",
    "# define the command\n",
    "# python3.10 -m torch.distributed.run --nproc_per_node=4 --master_port=12345 train.py --model_name_or_path ${{inputs.base_model}} --data_path ${{inputs.train_data}} --fp16 True --output_dir ./outputs --num_train_epochs 5 --model_max_length 512 --per_device_train_batch_size 2 --per_device_eval_batch_size 2 --gradient_accumulation_steps 3 --evaluation_strategy 'no' --save_strategy 'steps' --save_steps 50000 --save_total_limit 1 --learning_rate 1e-5 --weight_decay 0. --warmup_ratio 0.02 --lr_scheduler_type 'cosine' --logging_steps 1 --fsdp 'shard_grad_op auto_wrap' --tf32 True --report_to 'mlflow'\n",
    "command_job = command(\n",
    "    code=BASE_DIR,\n",
    "    # change point\n",
    "    command=cmd,\n",
    "    environment=env,\n",
    "    compute=f\"{gpu_compute_target}\",\n",
    "    timeout=180000,\n",
    "    outputs={\n",
    "        \"model_output\": Output(\n",
    "            type=\"uri_folder\",\n",
    "            path=output_path,\n",
    "            mode=\"rw_mount\"\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97162b8b-f511-4963-acf2-9aa8b8f1a89c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ジョブ投入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4c73b0-cc63-414b-b7e8-c77f05cbb7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the command\n",
    "returned_job = ml_client.jobs.create_or_update(\n",
    "    # jobを指定\n",
    "    command_job,\n",
    "    # ディスプレイ名を設定 \n",
    "    display_name=job_name + \"_\" + train_type,\n",
    "    # ジョブ名を設定 \n",
    "    experiment_name=job_name\n",
    ")\n",
    "# get a URL for the status of the job\n",
    "returned_job.studio_url"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
